{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6222ef-bcf5-4607-b6e3-a8adc1526d98",
   "metadata": {},
   "source": [
    "# RAG (Retrieval Augmented Generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97832a81-e9e9-4399-a89e-834d45c65b8f",
   "metadata": {},
   "source": [
    "#### What is RAG?\n",
    "**Retrieval Augmented Generation** is a way to improve how AI models, like chatbots, generate the text. It combines the AI's ability to create text with a system that finds and uses relevant information from a database/knowledge base.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b4b539-e522-4070-9c31-391aa7094aa6",
   "metadata": {},
   "source": [
    "#### How Does RAG Work?\n",
    "1. **You ask a question/query**: You ask the Chatbot something.\n",
    "2. **Find relevant information for you**: The Chatbot searches a knowledge-base to find the most relevant information related to your question/query.\n",
    "3. **Genearate accurate response**: The Chatbot uses this information to create a more accurate answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68080cd7-47ae-4bea-95ba-4a545a38bf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.12/site-packages (25.0.1)\n",
      "Requirement already satisfied: Cmake in /opt/conda/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "# Installing required packages\n",
    "!pip install --upgrade pip\n",
    "!pip install langchain -q\n",
    "!pip install langchain_community -q\n",
    "!pip install chromadb -q\n",
    "!pip install Cmake\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "72f92b7f-76df-4e70-a143-30469752b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the required libraries and modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "from typing import Any, List\n",
    "from pydantic import Field, BaseModel, Extra\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import FakeEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA, LLMChain, ConversationalRetrievalChain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.memory import ConversationSummaryMemory, ConversationBufferMemory\n",
    "from langchain.schema import BaseRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.chains.combine_documents.refine import RefineDocumentsChain\n",
    "from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f552825-5d3d-4676-af81-eb20b9485c33",
   "metadata": {},
   "source": [
    "### LangChain & Ollama\n",
    "\n",
    "Over here we're working with LangChain, which is a powerful framework for building applications with language models.\n",
    "LangChain provides utilities for working with various language model providers, integrating embeddings, and even creating chains for more complex applications. \n",
    "\n",
    "LangChain is especially useful for creating Retrieval Augmented Generation (RAG) workflows, which improve response accuracy by combining LLMs with real-time data retrieval. It’s open-source, flexible, and widely used across industries for building scalable and efficient AI solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b52201d-e32a-42ac-bbcc-8f86c7ba50a9",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "We're using Ollama, which a platform for running LLMs on your local machine. \n",
    "To get started with Ollama for our RAG tutorial, follow these simple steps:\n",
    "\n",
    "1. Open up a terminal window in JupyterLab and type: `ollama serve` (This fires up the Ollama service, which acts like a local AI assistant.)\n",
    "\n",
    "2. Now, open another terminal window in JupyterLab. Here, we'll download the Mistral model by typing: `ollama pull mistral` (This grabs the Mistral model and makes it ready for use on your computer.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966e65fa-5584-471f-a487-fa64e933a141",
   "metadata": {},
   "source": [
    "### Part-1: Retrieval\n",
    "\n",
    "* In this section, we'll more focus on the retrieval part of the RAG by understanding vectorization, followed by storing and retrieving vectors efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f5930-d898-407b-bec4-cca51f94694b",
   "metadata": {},
   "source": [
    "#### Vectorization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e5ab1c3-fdf7-4fb1-8e4f-ad67c0918b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.12/site-packages (25.0.1)\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gptqmodel 1.9.0 requires numpy>=2.2.2, but you have numpy 2.1.3 which is incompatible.\n",
      "gptqmodel 1.9.0 requires protobuf>=5.29.3, but you have protobuf 4.25.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\n",
      "gptqmodel 1.9.0 requires protobuf>=5.29.3, but you have protobuf 4.25.6 which is incompatible.\n",
      "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install tf-keras --upgrade -q\n",
    "!pip install --upgrade transformers numpy sentence-transformers langchain_community -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d555076-1fd3-4277-8313-484f24f05a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initializing the vectorizer\n",
    "# \"all-MiniLM-L6-v2\": is a good general-purpose embedding model that balances performance and efficiency\n",
    "vectorizer = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\") # This vectorizer converts text into vectors in embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485303d5-0e7d-40eb-a82e-759c95d1d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take an example of converting \"CSUCO\" into a series of numbers\n",
    "vectorizer.embed_query(\"CSUCO\")[0:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63458a05-eb27-450d-bc49-60a4484b9ad7",
   "metadata": {},
   "source": [
    "Here, we'll write one function that takes 2 strings, vectorizes them, and returns their cosine similarity. \n",
    "\n",
    "**Cosine Similarity**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852768ab-a059-44eb-9ba5-13cfb9c2d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_score(word1, word2):\n",
    "    \"\"\" Helper function to vectorize two strings and return the cosine similarity \"\"\"\n",
    "    word1_vector = vectorizer.embed_query(word1)\n",
    "    word2_vector = vectorizer.embed_query(word2)\n",
    "    dot_product = np.dot(word1_vector, word2_vector)\n",
    "    norm_vec1 = np.linalg.norm(word1_vector)\n",
    "    norm_vec2 = np.linalg.norm(word2_vector)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49f5438-5e97-43f8-b8ac-31c95dd6aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe the similarity scores\n",
    "# From similarity score you can quantify how similar both words are.\n",
    "\n",
    "print(\"Similarity of 'colour' and 'color': \",get_similarity_score(\"colour\",\"color\"))\n",
    "print(\"Similarity of 'cars' and 'car': \",get_similarity_score(\"cars\",\"car\"))\n",
    "print(\"Similarity of 'cars' and 'truck': \",get_similarity_score(\"cars\",\"truck\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58cdd40-fd06-4b25-a9b3-d8d2371723d3",
   "metadata": {},
   "source": [
    "Which of the following words in the list words are most related to the word **'car'**? The function similarity_list takes a list of words, and outputs the word and similarity score from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e592baf-5a8e-410f-9679-0349202eab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_list(words):\n",
    "    \"\"\" Helper function that return a list of tuples with (word, cosine similarity) for words in the list relative to 'car', sorted by similarity descending.\"\"\"\n",
    "    car = \"car\"\n",
    "    results = [(word, get_similarity_score(car, word)) for word in words]\n",
    "    return sorted(results, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a0f14-0250-4029-8aad-343dafb2e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"cars\", \"truck\", \"bike\", \"trees\", \"mountains\"]\n",
    "similarity_list(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86124774-0877-4efc-b3a7-b25ecb4e8a42",
   "metadata": {},
   "source": [
    "Here, we'll write a function that matches a query with its most related/relevant text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11bd580-dcf1-41d8-bb7b-b6f077fa3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each query below has an appropriate text that allows you to answer the question.\n",
    "# Example list of existing query-text pairs\n",
    "qa_pairs = [\n",
    "    {\"query\": \"What is RAG?\", \"text\": \"Retrieval Augmented Generation improves response accuracy by combining retrieval with generation.\"},\n",
    "    {\"query\": \"How does vectorization help?\", \"text\": \"Vectorization converts text into numerical representations that models can work with.\"},\n",
    "    {\"query\": \"What is the importance of embeddings?\", \"text\": \"Embeddings allow machine learning models to understand text by converting words into vectors.\"},\n",
    "    {\"query\": \"How do retrieval systems work?\", \"text\": \"Retrieval systems search large databases and find the most relevant documents based on the query.\"},\n",
    "    {\"query\": \"Why is local LLM deployment beneficial?\", \"text\": \"Deploying LLMs locally can reduce latency and improve data privacy.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6fd012-291f-47e0-ba90-eb3b55c65665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_queries_with_pairs(queries, qa_pairs):\n",
    "    \"\"\" Helper function that matches each query with the most related text from qa_pairs based on cosine similarity \"\"\"\n",
    "    matched_results = []\n",
    "    for query in queries:\n",
    "        best_match = None\n",
    "        best_score = -1\n",
    "        for pair in qa_pairs:\n",
    "            score = get_similarity_score(query, pair[\"text\"])\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = pair\n",
    "        matched_results.append({\"query\": query, \"matched_text\": best_match[\"text\"], \"similarity\": best_score})\n",
    "    return matched_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f019ba-c4a1-4e59-b6ad-ea93b041dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"What is RAG?\", \"How are embeddings used?\", \"Benefits of local LLMs?\"]\n",
    "matches = match_queries_with_pairs(queries, qa_pairs)\n",
    "for match in matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e88b9-11d4-4e54-bb12-95e6e147059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now separate the queries and text\n",
    "\n",
    "queries = [\"What is RAG?\",\n",
    "            \"How does vectorization help?\",\n",
    "            \"What is the importance of embeddings?\",\n",
    "            \"How do retrieval systems work?\",\n",
    "            \"Why is local LLM deployment beneficial?\"]\n",
    "\n",
    "texts = [\"Retrieval Augmented Generation improves response accuracy by combining retrieval with generation.\",\n",
    "         \"Vectorization converts text into numerical representations that models can work with.\",\n",
    "         \"Embeddings allow machine learning models to understand text by converting words into vectors.\",\n",
    "         \"Retrieval systems search large databases and find the most relevant documents based on the query.\",\n",
    "         \"Deploying LLMs locally can reduce latency and improve data privacy.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f461b-13a2-4965-ad03-149700a02d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_queries_with_texts(queries, texts):\n",
    "    \"\"\" Helper function that matches each query with the most related text based on cosine similarity \"\"\"\n",
    "    \n",
    "    # Calculate similarities between each query and text\n",
    "    similarities = np.zeros((len(queries), len(texts)))\n",
    "    \n",
    "    for i, query in enumerate(queries):\n",
    "        for j, text in enumerate(texts):\n",
    "            similarities[i, j] = get_similarity_score(query, text)\n",
    "    \n",
    "    # Match each query to the text with the highest similarity\n",
    "    matches = {}\n",
    "    for i, query in enumerate(queries):\n",
    "        best_match_idx = np.argmax(similarities[i])\n",
    "        matches[query] = texts[best_match_idx]\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdcc935-7c11-4b2b-ae6a-c1b501fc5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's shuffle the queries and texts \n",
    "\n",
    "import random\n",
    "random.shuffle(queries)\n",
    "random.shuffle(texts)\n",
    "\n",
    "match_queries_with_texts(queries, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a49e44-abd0-456c-aad2-c630c552fa54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa1dd56f-4156-404f-8fb5-3f6e9b6c7f8d",
   "metadata": {},
   "source": [
    "### Database: ChromaDB\n",
    "\n",
    "Let us see how we can store these for efficient vector retrieval. There are many storage options available, but here we will use **ChromaDB**, an open-source vector database.\n",
    "\n",
    "In LangChain, we can set the database to be a LangChain **retriever object**, which essentially allows us to **perform queries similarly**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94316d7e-eba3-40e7-98f6-c02728f2faac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f9822-e42f-4055-90a8-78557e8084bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First just to give it a try, store the already defined queries and texts and load them into ChromaDB\n",
    "\n",
    "ids = list(range(len(texts)))\n",
    "db = Chroma.from_texts(texts, vectorizer, metadatas=[{\"id\":id} for id in ids])\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b347f4-a2f5-43c4-bbe4-a2b717d85ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to get texts and the metadata\n",
    "\n",
    "retriever.invoke('What is RAG?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f6384-e50d-46ba-9f61-a15d5430e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke('What is the importance of embeddings?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314504d-2966-4e78-b8dd-40d3867acc26",
   "metadata": {},
   "source": [
    "Now, I'll apply the same retrieval logic to a file `policy_report.csv` that contains various information (Title, Area and Owner) of several policies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf70b4f7-b0c0-4177-a60e-50d94e6acf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_policy_retriever(csv_file, top_k=10, combine_fields=False):\n",
    "    \"\"\" Helper function that reads a CSV file containing policy data (title, areas and owner) and return a ChromaDB retriever \"\"\"\n",
    "    try:\n",
    "        # Try reading with the default engine and UTF-8 encoding\n",
    "        df = pd.read_csv(csv_file, encoding=\"utf-8\", sep=\"\\t\", on_bad_lines='skip')\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Failed to decode with encoding utf-8. Trying 'utf-16' instead.\")\n",
    "        df = pd.read_csv(csv_file, encoding=\"utf-16\", sep=\"\\t\", on_bad_lines='skip')\n",
    "\n",
    "    required_columns = {'Title', 'Area', 'Owner'}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        raise ValueError(f\"CSV file must contain the columns: {required_columns}\")\n",
    "\n",
    "    texts = []\n",
    "    metadatas = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if combine_fields:\n",
    "            # Combine all fields into the text for richer context\n",
    "            text = f\"Title: {row['Title']}\\nArea: {row['Area']}\\nOwner: {row['Owner']}\"\n",
    "        else:\n",
    "            # Use only the title as the main text\n",
    "            text = row['Title']\n",
    "        metadata = {\"Area\": row['Area'], \"Owner\": row['Owner']}\n",
    "        texts.append(text)\n",
    "        metadatas.append(metadata)\n",
    "\n",
    "    # Create the vector store with the provided texts and metadata\n",
    "    db = Chroma.from_texts(texts, vectorizer, metadatas=metadatas)\n",
    "    \n",
    "    # Convert the vector store into a retriever object with the specified top_k results.\n",
    "    retriever = db.as_retriever(search_kwargs={\"k\": top_k})\n",
    "    \n",
    "    # Extra feature: Log the number of policies loaded.\n",
    "    print(f\"Loaded {len(texts)} policies into the vector store.\")\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70a479-cfd7-4c35-a032-7fc5c73ca35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = create_policy_retriever(\"policy_report.csv\", top_k=5, combine_fields=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd43fa7-19c5-4cd6-9fae-7023dedd270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke('Budget Oversight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a805f19-7294-4ea7-bd3d-c91b32caba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke('Accounting for Banking Activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a2672-c31b-44b4-a9a0-04dfe27325bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_policy(retriever, query):\n",
    "    \"\"\" Helper function to query the retriever for a policy and print the matching policy details in a table format. \"\"\"\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    policies = []\n",
    "    for doc in results:\n",
    "        metadata = doc.metadata\n",
    "        title = doc.page_content\n",
    "        # Use the correct case keys based on your metadata (e.g., 'Area' and 'Owner')\n",
    "        area = metadata.get('Area')\n",
    "        owner = metadata.get('Owner')\n",
    "        policies.append({\"Title\": title, \"Area\": area, \"Owner\": owner})\n",
    "\n",
    "    df = pd.DataFrame(policies)\n",
    "    print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b4963c-ab7c-444d-9017-7b1d10b0af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_policy(retriever, \"Academic and Student Affairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c95ae-2838-4cca-93b0-8a4aed471660",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_policy(retriever, \"Business and Finance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b99c25-d299-4660-8845-098fd6a8ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy_titles_by_area(retriever, area_query, max_results=1000, sort_results=False, return_full_info=False):\n",
    "    \"\"\" Helper function that takes an area query string, return a list of policy titles \n",
    "    or full policy details whose metadata \"Area\" matches the area_query return List of policy titles (str) or list of dictionaries \n",
    "    with full info.\"\"\"\n",
    "    \n",
    "    results = retriever.get_relevant_documents(\"\", filter={\"Area\": area_query}, k=max_results)\n",
    "    \n",
    "    policies = []\n",
    "    for doc in results:\n",
    "        if doc.page_content.startswith(\"Title:\"):\n",
    "            first_line = doc.page_content.split(\"\\n\")[0]\n",
    "            title = first_line.replace(\"Title: \", \"\").strip()\n",
    "        else:\n",
    "            title = doc.page_content.strip()\n",
    "        policy_info = {\"Title\": title, \"Area\": doc.metadata.get(\"Area\"), \"Owner\": doc.metadata.get(\"Owner\")}\n",
    "        policies.append(policy_info)\n",
    "    \n",
    "    if sort_results:\n",
    "        policies = sorted(policies, key=lambda x: x[\"Title\"])\n",
    "    \n",
    "    print(f\"Found {len(policies)} matching policies for area '{area_query}'.\")\n",
    "    \n",
    "    if return_full_info:\n",
    "        return policies\n",
    "    else:\n",
    "        return [p[\"Title\"] for p in policies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c2c775-533c-4576-822a-f0c4ecd4e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"Academic and Student Affairs\"\n",
    "titles = get_policy_titles_by_area(retriever, area, max_results=100, sort_results=True, return_full_info=False)\n",
    "print(\"Policy Titles for area '{}':\".format(area))\n",
    "for t in titles:\n",
    "    print(\"-\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51533a03-2ede-4f3a-8198-d25e0d45ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = \"Business and Finance\"\n",
    "titles = get_policy_titles_by_area(retriever, area, max_results=100, sort_results=True, return_full_info=True)\n",
    "print(\"Policy Titles for area '{}':\".format(area))\n",
    "for t in titles:\n",
    "    print(\"-\", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8679c617-0885-4504-9d78-d51d99d4da9a",
   "metadata": {},
   "source": [
    "### Chunking\n",
    "\n",
    "The data we just looked at was conveniently split into rows, with each row representing a distinct and meaningful chunk of information. This straightforward structure makes it easier to process and analyze the text data.\n",
    "\n",
    "However, when dealing with larger or more complex documents, the text is often not so neatly structured. In such cases, it’s essential to handle the formatting and structure efficiently. We can break down a not-so-simply formatted file into manageable chunks using LangChain's `TextLoader` and `RecursiveCharacterTextSplitter`. This allows us to preprocess and chunk the data effectively for further use in our RAG pipeline.\n",
    "\n",
    "#### Example Code\n",
    "\n",
    "```python\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load text data from a file\n",
    "loader = TextLoader(\"your_document.txt\")  # Replace with your file path\n",
    "documents = loader.load()\n",
    "\n",
    "# Initialize the text splitter with a defined chunk size and overlap\n",
    "# - chunk_size: The maximum number of characters in each chunk.\n",
    "# - chunk_overlap: The number of overlapping characters between chunks.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "# Split the loaded documents into chunks\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Display the number of chunks created\n",
    "print(f\"Total chunks\n",
    "created: {len(chunks)}\")\n",
    "ine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987287f-b99b-440c-b930-83fdca8d7d9f",
   "metadata": {},
   "source": [
    "Let me upload a policy document here and try to perform the same retrieval logic before doing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae2493-193b-409d-8ace-cc27b662c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf\n",
    "\n",
    "source_url = \"http://calstate.policystat.com/policy/17347260/\"\n",
    "pdf_file = \"Policies/Academic Freedom Policy.pdf\"\n",
    "pdf_loader = PyPDFLoader(pdf_file)\n",
    "documents = pdf_loader.load()\n",
    "print(f\"Loaded {len(documents)} document(s) from '{pdf_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a528906-b5ad-430b-9b46-196e55909fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small chunk size\n",
    "small_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "small_chunks = small_text_splitter.split_documents(documents)\n",
    "print(f\"Document has been splitted into {len(small_chunks)} small chunks.\")\n",
    "\n",
    "# Large chunk size\n",
    "large_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "large_chunks = large_text_splitter.split_documents(documents)\n",
    "print(f\"Document has been splitted into {len(large_chunks)} large chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a6ab7-6f73-40fa-8e9b-9d2e69336405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating ChromaDB retriever for small chunks\n",
    "db_small = Chroma.from_documents(small_chunks, vectorizer)\n",
    "retriever_small = db_small.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# Creating ChromaDB retriever for large chunks\n",
    "db_large = Chroma.from_documents(large_chunks, vectorizer)\n",
    "retriever_large = db_large.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39e759-cad4-4bb6-984c-b0ea6796474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_retrieval(query, retriever):\n",
    "    \"\"\" Helper function that retrieves relevant chunks for the given query using the provided retriever. \"\"\"\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    print(f\"Query: {query} \\n\")\n",
    "    print(f\"Retrieved {len(results)} results from retriever.\\n\")\n",
    "    \n",
    "    for i, doc in enumerate(results, start=1):\n",
    "        chunk_text = doc.page_content\n",
    "        chunk_length = len(chunk_text)\n",
    "        print(f\"[Result {i}] - Length: {chunk_length} characters\")\n",
    "        print(chunk_text)\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb5c06-9f48-4bb9-a68f-4c09c30e7dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NEED TO LOOK AGAIN ON THIS PART\n",
    "\n",
    "query = \"How does the policy address controversial topics in the classroom?\"\n",
    "\n",
    "# Trying to fetch the relevant information using small_retriever\n",
    "chunk_retrieval(query, retriever_small)\n",
    "\n",
    "# Trying to fetch the relevant information using large_retriever   \n",
    "chunk_retrieval(query, retriever_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795499f-be02-4257-b219-932eece1f349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce6e8622-8dd7-45a6-a856-0f684c815e37",
   "metadata": {},
   "source": [
    "### RAG With LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a0c25-b842-4992-9717-78faea307a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking while preserving page metadata\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035ad1d-fcc5-46d6-9caa-771afbf17b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting each page into smaller chunks and preserving metadata\n",
    "for doc in documents:\n",
    "    doc.metadata[\"source\"] = source_url\n",
    "\n",
    "all_chunks = []\n",
    "for doc in documents:\n",
    "    # Using metadata from the original page (like 'page' or 'source')\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata = doc.metadata  # Retaining the original page's metadata\n",
    "        all_chunks.append(chunk)\n",
    "\n",
    "print(f\"Total chunks after splitting: {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f75486-9539-4595-9bae-5de10da58f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store from chunks (with page metadata now preserved!)\n",
    "db = Chroma.from_documents(all_chunks, vectorizer)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fadd6a-7573-41ab-af1f-5d50e633d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"mistral\", temperature=0.7)\n",
    "llm.invoke(\"Hello there, how are you doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a543d47-6daa-4251-a6ea-a7401405ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a89c5b1-0d7c-4c1d-9dfb-bc07ba8422fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What responsibilities accompany academic freedom, as outlined in the policy?\"\n",
    "result = rag_chain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5840cce-2e7c-40f7-99ef-dc460835e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48601d8-a82d-4e33-84af-5c3b88775195",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Query: {query} \")\n",
    "print(f\"Answer: {result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb2dfc-9557-4543-8e4b-622d04c1030b",
   "metadata": {},
   "source": [
    "#### Adding custom prompts and refine question prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f1aa1-0864-4077-a404-2ce21b3eda72",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_prompt_template = \"\"\"\n",
    "You're a highly knowledgeable assistant. I want you to answer the following question using the context provided.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "refine_prompt_template = \"\"\"\n",
    "The initial answer is: {existing_answer}\n",
    "Additional context: {context}\n",
    "Please refine and elaborate on the answer, providing clear details and citing evidence where applicable.\n",
    "Refined answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d2737-4a67-4149-aadc-90eca81476a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_prompt = PromptTemplate(template=question_prompt_template, input_variables=[\"question\", \"context\"])\n",
    "refine_prompt = PromptTemplate(template=refine_prompt_template, input_variables=[\"existing_answer\", \"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573433b0-cfb9-4388-b9ef-007143d8fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the advanced RAG chain using RetrievalQA with the \"refine\" strategy\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"question_prompt\": question_prompt,\n",
    "        \"refine_prompt\": refine_prompt,\n",
    "        \"document_variable_name\": \"context\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944564c-ff81-4d00-bb7b-6f8802b96c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_sources(source_documents):\n",
    "    \"\"\" Helper function that summarizes the source documents. \"\"\"\n",
    "    summary_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "    summary = summary_chain.run(source_documents)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518c130-e632-4686-8687-158658ab4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining RAG pipeline\n",
    "def rag_pipeline(query):\n",
    "    \"\"\" Helper function that runs a RAG pipeline with custom refine prompts, evidence summarization, and references of source documents. \"\"\"\n",
    "    result = rag_chain(query)\n",
    "    answer = result['result']\n",
    "    source_docs = result['source_documents']\n",
    "\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Answer: {answer}\\n\")\n",
    "    print(\"-\" * 100)\n",
    "    summary = summarize_sources(source_docs)\n",
    "    print(f\"Summary from Source Documents: {summary}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    print(\"\\nReferences (click to view source page):\\n\")\n",
    "    for i, doc in enumerate(source_docs, start=1):\n",
    "        metadata = doc.metadata\n",
    "        page = metadata.get(\"page\")\n",
    "        source = metadata.get(\"source\")\n",
    "\n",
    "        if source and page is not None:\n",
    "            link = f\"{source}#page={page + 1}\"\n",
    "            print(f\"[{i}] Page {page + 1}: {link}\")\n",
    "        elif source:\n",
    "            print(f\"[{i}] Source: {source}\")\n",
    "        else:\n",
    "            print(f\"[{i}] Source: Unknown\")\n",
    "\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b250d-955f-473d-95e5-4d4bd43f9a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is responsible for overseeing the academic freedom policy and what are their roles?\"\n",
    "rag_pipeline(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41a001-45ef-4a48-9c01-649a45fb9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What procedures are specified for the review and revision of the academic freedom policy?\"\n",
    "rag_pipeline(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b7a7fe-13b1-4170-8cbd-9983a0fe7f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the key principles that define academic freedom as outlined in the policy?\"\n",
    "rag_pipeline(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be41fe-4b19-4a16-b4bf-53d6b69c22ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03a200a0-fdcd-4844-9d35-4e0c4ff22828",
   "metadata": {},
   "source": [
    "# RAG with multiple Policies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d853221d-029a-417f-9343-67b7970f7222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# STEP 1: Load the CSV Report with Policy Metadata\n",
    "#############################################################\n",
    "\n",
    "def load_policy_report(csv_file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the report.csv that includes policy titles and reference URLs.\n",
    "    Expected CSV columns: 'Title', 'URL', and potentially others.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try reading with the default engine and UTF-8 encoding\n",
    "        df = pd.read_csv(csv_file, encoding=\"utf-8\", sep=\"\\t\", on_bad_lines='skip')\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Failed to decode with encoding utf-8. Trying 'utf-16' instead.\")\n",
    "        df = pd.read_csv(csv_file, encoding=\"utf-16\", sep=\"\\t\", on_bad_lines='skip')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34616ca1-5e29-456e-839e-d0e8dfb19b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode with encoding utf-8. Trying 'utf-16' instead.\n",
      "Report loaded: 429 policies found in report.csv.\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file (adjust the path if needed)\n",
    "report_df = load_policy_report(\"report.csv\")\n",
    "print(f\"Report loaded: {len(report_df)} policies found in report.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f506444a-c810-4ed2-b097-31aee5373637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode with encoding utf-8. Trying 'utf-16' instead.\n",
      "[INFO]: Report loaded with 428 policies.\n"
     ]
    }
   ],
   "source": [
    "def map_policy_metadata(report_df: pd.DataFrame) -> dict:\n",
    "    \"\"\" Helper function that creates a mapping where keys are lowercase policy titles (from the CSV) and values are the corresponding URL. \"\"\"\n",
    "    mapping = {}\n",
    "    for _, row in report_df.iterrows():\n",
    "        title = row[\"Title\"].strip().lower()\n",
    "        url = row[\"URL\"].strip()\n",
    "        mapping[title] = url\n",
    "    return mapping\n",
    "\n",
    "# Load CSV and create mapping.\n",
    "report_df = load_policy_report(\"report.csv\")\n",
    "policy_mapping = map_policy_metadata(report_df)\n",
    "print(f\"[INFO]: Report loaded with {len(policy_mapping)} policies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6998c88c-eec7-4378-a9d9-63b71d95c956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3139 document pages from policies.\n"
     ]
    }
   ],
   "source": [
    "# First, I'm trying to all the Policy documents (pdfs), chunking them while preserving the metadata of each policy document.\n",
    "def load_policies(folder_path: str, policy_mapping: dict) -> List[Document]:\n",
    "    \"\"\" Helper function that loads all PDFs from the folder and update each Document's metadata with. \"\"\"\n",
    "    all_docs = []\n",
    "    for pdf_path in Path(folder_path).glob(\"*.pdf\"):\n",
    "        loader = PyPDFLoader(str(pdf_path))\n",
    "        docs = loader.load()  \n",
    "        file_title = pdf_path.stem.lower()\n",
    "        matched_url = None\n",
    "        matched_policy_title = None\n",
    "\n",
    "        for title_key, url in policy_mapping.items():\n",
    "            if title_key in file_title:\n",
    "                matched_url = url\n",
    "                matched_policy_title = title_key  \n",
    "                break\n",
    "        for doc in docs:\n",
    "            doc.metadata[\"source_file\"] = pdf_path.name\n",
    "            if matched_url:\n",
    "                doc.metadata[\"policy_title\"] = matched_policy_title\n",
    "                doc.metadata[\"policy_url\"] = matched_url\n",
    "            else:\n",
    "                # Fallback if no match is found in the CSV.\n",
    "                doc.metadata[\"policy_title\"] = pdf_path.stem\n",
    "                doc.metadata[\"policy_url\"] = None\n",
    "        all_docs.extend(docs)\n",
    "    return all_docs\n",
    "\n",
    "raw_documents = load_policies(\"Policies/\", policy_mapping)\n",
    "print(f\"Loaded {len(raw_documents)} document pages from policies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46c7745b-61be-4213-a44c-4beb440e4a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Loaded 3139 documents (pages) from the 'Policies/' folder.\n"
     ]
    }
   ],
   "source": [
    "print(f\"[INFO]: Loaded {len(raw_documents)} documents (pages) from the 'Policies/' folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ba1df-8fb4-4bb6-a5c8-c5e27ea7d600",
   "metadata": {},
   "source": [
    "Update Document Metadata from CSV Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4af1947-8588-4311-bd00-be3fe0f66c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_doc_metadata_with_report(docs: List[Document], report_df: pd.DataFrame) -> List[Document]:\n",
    "#     \"\"\" Helper function that uses the 'source_file' and the CSV report to update metadata for each policy document. \"\"\"\n",
    "#     for doc in docs:\n",
    "#         source_file = doc.metadata.get(\"source_file\", \"\").lower()\n",
    "#         matches = report_df[report_df[\"Title\"].str.lower().str.contains(source_file, na=False)]\n",
    "#         if not matches.empty:\n",
    "#             row = matches.iloc[0]\n",
    "#             doc.metadata[\"policy_title\"] = row[\"Title\"]\n",
    "#             doc.metadata[\"policy_url\"] = row[\"URL\"]\n",
    "#         else:\n",
    "#             doc.metadata[\"policy_title\"] = source_file\n",
    "#             doc.metadata[\"policy_url\"] = None\n",
    "#     return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecc6d844-52d7-474e-a9ee-f3726fb89738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_documents = update_doc_metadata_with_report(raw_documents, report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2039c930-ec6d-4009-96c6-946fc4f66351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking each document (policy) page while preserving the metadata\n",
    "def chunk_documents(raw_docs: list[Document], chunk_size: int = 500, overlap: int = 50) -> list[Document]:\n",
    "    \"\"\" Helper function that chunks each document and preserve the metadata. \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
    "    chunks = []\n",
    "    for doc in raw_docs:\n",
    "        doc_chunks = splitter.split_documents([doc])\n",
    "        for chunk in doc_chunks:\n",
    "            chunk.metadata = doc.metadata.copy()  # Preserve original metadata\n",
    "            chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ea3a9d1-a643-4f50-b596-b19ff57fae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Chunked into 18115 segments.\n"
     ]
    }
   ],
   "source": [
    "chunked_docs = chunk_documents(raw_documents)\n",
    "print(f\"[INFO]: Chunked into {len(chunked_docs)} segments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ca7ffcd-4bdf-431a-83f4-5cdd5fd58877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_filter_metadata(metadata: dict, allowed_types=(str, int, float, bool)) -> dict:\n",
    "    \"\"\" \n",
    "    Helper function that filters a metadata dictionary so that each value is of type str, int, float, or bool.\n",
    "    If a value is not one of these types (and not None), it's converted to a string.\n",
    "    Keys with None values are dropped.\n",
    "    \"\"\"\n",
    "    filtered = {}\n",
    "    for key, value in metadata.items():\n",
    "        if value is None:\n",
    "            continue  # Skip None values\n",
    "        if isinstance(value, allowed_types):\n",
    "            filtered[key] = value\n",
    "        else:\n",
    "            # Optionally, convert the value to a string.\n",
    "            filtered[key] = str(value)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5cb19ee-a484-42a5-a286-621426355163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Semantic retriever set up.\n"
     ]
    }
   ],
   "source": [
    "# Building Semantic & Keyword based Retriever\n",
    "\n",
    "# After chunking, I'm filtering metadata for each document chunk.\n",
    "# I'm replacing any None values with a default, or removes keys with non-simple types.\n",
    "for doc in chunked_docs:\n",
    "    doc.metadata = simple_filter_metadata(doc.metadata)\n",
    "\n",
    "db_semantic = Chroma.from_documents(chunked_docs, vectorizer)\n",
    "semantic_retriever = db_semantic.as_retriever(search_kwargs={\"k\": 5})\n",
    "print(\"[INFO]: Semantic retriever set up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ec9b438-8068-4f7b-b92b-9393f0a9082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Keyword retriever set up.\n"
     ]
    }
   ],
   "source": [
    "# Using FakeEmbeddings for keyword search (BM25-like retrieval)\n",
    "\n",
    "db_keyword = FAISS.from_documents(chunked_docs, FakeEmbeddings(size=768))\n",
    "keyword_retriever = db_keyword.as_retriever(search_kwargs={\"k\": 5})\n",
    "print(\"[INFO]: Keyword retriever set up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168bad25-e9b6-46af-b50c-c031e214b330",
   "metadata": {},
   "source": [
    "#### Building GraphRAG Component\n",
    "\n",
    "Overhere, I'm trying to build a graph over document chunk using NetworkX, where nodes represent chunks and edges connect similar chunks.  This graph helps propagate context across policy boundaries. \n",
    "\n",
    "This graph leverages approximate nearest neighbor search via FAISS to build a sparse graph over our policy documents chunks. This approach avoids computing all pairwise similarities (which can be prohibitively expensive for 500+ PDFs) by efficiently retrieving only the nearest neighbors for each chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4fa1967-cc06-40cf-b910-4d08aaae4b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Approach: I'm using FAISS IndexIVFFlat to perform approximate nearest neighbor search. Over here, an edge is added between two nodes if their inner product (cosine similarity) exceeds the specified threshold.\n",
    "'''\n",
    "\n",
    "def build_policy_graph(\n",
    "    docs: list[Document], \n",
    "    vectorizer, \n",
    "    k_neighbors: int = 5, \n",
    "    threshold: float = 0.9, \n",
    "    nlist: int = 100\n",
    ") -> nx.Graph:\n",
    "    \"\"\" Helper function that build a graph. \"\"\"\n",
    "\n",
    "    # Computing embeddings for each document chunk\n",
    "    embeddings = []\n",
    "    for doc in docs:\n",
    "        emb = np.array(vectorizer.embed_query(doc.page_content)).astype(\"float32\")\n",
    "        embeddings.append(emb)\n",
    "    embeddings = np.stack(embeddings)\n",
    "    dim = embeddings.shape[1]\n",
    "\n",
    "    # Building an approximate FAISS index with inner-product\n",
    "    quantizer = faiss.IndexFlatIP(dim)\n",
    "    index = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "    index.train(embeddings)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    # Retrieving approximate k_neighbors for each chunk (include self in results)\n",
    "    # returns: D = distances, I = Indices\n",
    "    D, I = index.search(embeddings, k_neighbors + 1)\n",
    "\n",
    "    # Building a graph based on neighbors with similarity above threshold\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Adding nodes with metadata (source and page)\n",
    "    for idx, doc in enumerate(docs):\n",
    "        G.add_node(idx, doc=doc)\n",
    "\n",
    "    # For each document, adding edges from its approximate neighbors (skipping self)\n",
    "    for i, (neighbors, distances) in enumerate(zip(I, D)):\n",
    "        for j, sim in zip(neighbors[1:], distances[1:]):\n",
    "            if sim >= threshold:\n",
    "                # Adding an edge with weight=similarity\n",
    "                G.add_edge(i, j, weight=float(sim))\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "571caf99-1373-457b-8bc0-6ba13d33efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Approximate graph created with 18115 nodes and 7435 edges.\n"
     ]
    }
   ],
   "source": [
    "# Building the graph on our chunked documents \n",
    "\n",
    "policy_graph = build_policy_graph(chunked_docs, vectorizer, k_neighbors=5, threshold=0.9, nlist=100)\n",
    "print(f\"[INFO]: Approximate graph created with {policy_graph.number_of_nodes()} nodes and {policy_graph.number_of_edges()} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2189987-a57d-45e8-8119-f5257e3b32ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Summary:\n",
      "  Number of nodes: 18115\n",
      "  Number of edges: 7435\n",
      "\n",
      "Sample Nodes (first 5):\n",
      "(0, {'doc': Document(metadata={'producer': 'Prince 12.5.1 (www.princexml.com)', 'creator': 'PolicyStat', 'creationdate': '', 'subject': 'The California State University', 'author': 'Grommo, April: Asst VC, Enroll Mgmt Srvcs', 'title': '2021 – 2022 Emergency Grant Allocation', 'source': 'Policies/2021 - 2022 Emergency Grant Allocation.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': '2021 - 2022 Emergency Grant Allocation.pdf', 'policy_title': '2021 - 2022 Emergency Grant Allocation'}, page_content='COPY\\nStatus Active PolicyStat ID 10719972 \\nOrigination 12/7/2021 \\nEffective 12/7/2021 \\nReviewed 12/7/2021 \\nNext Review 12/7/2023 \\nOwner April Grommo: \\nAsst VC, Enroll \\nMgmt Srvcs \\nArea Academic and \\nStudent Affairs \\n2021 – 2022 Emergency Grant Allocation \\nPolicy \\nThis policy provides procedural guidance related to the allocation of $30 million of one-time funding \\nissued under the Budget Act of 2021 for emergency financial assistance grants for low-income students.')})\n",
      "(1, {'doc': Document(metadata={'producer': 'Prince 12.5.1 (www.princexml.com)', 'creator': 'PolicyStat', 'creationdate': '', 'subject': 'The California State University', 'author': 'Grommo, April: Asst VC, Enroll Mgmt Srvcs', 'title': '2021 – 2022 Emergency Grant Allocation', 'source': 'Policies/2021 - 2022 Emergency Grant Allocation.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': '2021 - 2022 Emergency Grant Allocation.pdf', 'policy_title': '2021 - 2022 Emergency Grant Allocation'}, page_content='The $30 million is allocated to campuses by a pro-rata distribution based on the number of 2019-20 \\nstudents who were eligible to receive Pell Grant financial aid, as well as those who met the requirements \\nfor an exemption from paying nonresident tuition and the income criteria applicable to the California \\nDream Act application. \\nStudent Grant Eligibility \\nGrants are available to students that meet the following conditions:')})\n",
      "(2, {'doc': Document(metadata={'producer': 'Prince 12.5.1 (www.princexml.com)', 'creator': 'PolicyStat', 'creationdate': '', 'subject': 'The California State University', 'author': 'Grommo, April: Asst VC, Enroll Mgmt Srvcs', 'title': '2021 – 2022 Emergency Grant Allocation', 'source': 'Policies/2021 - 2022 Emergency Grant Allocation.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': '2021 - 2022 Emergency Grant Allocation.pdf', 'policy_title': '2021 - 2022 Emergency Grant Allocation'}, page_content='1. The student is currently enrolled in at least 6 semester units, or the quarter equivalent. \\n2. The student is able to demonstrate an emergency financial need, including loss of \\nemployment. \\n3. The student either currently qualifies as low income by meeting requirements to receive Pell \\nGrant financial aid for the upcoming semester or by meeting all the requirements for an \\nexemption from paying nonresident tuition pursuant to Section 68130.5 of the Education Code')})\n",
      "(3, {'doc': Document(metadata={'producer': 'Prince 12.5.1 (www.princexml.com)', 'creator': 'PolicyStat', 'creationdate': '', 'subject': 'The California State University', 'author': 'Grommo, April: Asst VC, Enroll Mgmt Srvcs', 'title': '2021 – 2022 Emergency Grant Allocation', 'source': 'Policies/2021 - 2022 Emergency Grant Allocation.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': '2021 - 2022 Emergency Grant Allocation.pdf', 'policy_title': '2021 - 2022 Emergency Grant Allocation'}, page_content=\"and the income criteria applicable to the California Dream Act application. \\n4. The student has either: \\na. Earned a grade point average of at least 2.0 in one of the student's previous three \\nsemester terms or in one of their previous four quarters, irrespective of whether that \\nterm occurred at the student's prior, or current, local educational agency, community \\ncollege, or four-year college; or \\nb. The student is disabled and receiving additional support or services through a\")})\n",
      "(4, {'doc': Document(metadata={'producer': 'Prince 12.5.1 (www.princexml.com)', 'creator': 'PolicyStat', 'creationdate': '', 'subject': 'The California State University', 'author': 'Grommo, April: Asst VC, Enroll Mgmt Srvcs', 'title': '2021 – 2022 Emergency Grant Allocation', 'source': 'Policies/2021 - 2022 Emergency Grant Allocation.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': '2021 - 2022 Emergency Grant Allocation.pdf', 'policy_title': '2021 - 2022 Emergency Grant Allocation'}, page_content='campus program for disabled students. \\nIn providing an emergency financial assistance grant to a student, to the extent that data is readily \\n2021 – 2022 Emergency Grant Allocation. Retrieved 3/27/2025. Official copy at http://calstate.policystat.com/policy/\\n10719972/. Copyright © 2025 The California State University\\nPage 1 of 3')})\n",
      "\n",
      "Sample Edges (first 5):\n",
      "(10, np.int64(2915), {'weight': 0.9395480155944824})\n",
      "(13, np.int64(8004), {'weight': 0.9599432349205017})\n",
      "(13, np.int64(8012), {'weight': 0.9582447409629822})\n",
      "(13, np.int64(10733), {'weight': 0.9572423696517944})\n",
      "(13, np.int64(11654), {'weight': 0.9570760726928711})\n"
     ]
    }
   ],
   "source": [
    "def print_policy_graph_info(graph):\n",
    "    ''' Helper function that return the summary of the Policy Graph. '''\n",
    "    print(\"Graph Summary:\")\n",
    "    print(f\"  Number of nodes: {graph.number_of_nodes()}\")\n",
    "    print(f\"  Number of edges: {graph.number_of_edges()}\")\n",
    "    print(\"\\nSample Nodes (first 5):\")\n",
    "    for node in list(graph.nodes(data=True))[:5]:\n",
    "        print(node)\n",
    "    print(\"\\nSample Edges (first 5):\")\n",
    "    for edge in list(graph.edges(data=True))[:5]:\n",
    "        print(edge)\n",
    "\n",
    "print_policy_graph_info(policy_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fc60e82-a51f-4aae-bafe-882e781638c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_prompt_template = \"\"\"\n",
    "# You are a highly knowledgeable assistant with expertise in CSU policies. Your task is to answer the following question using the context provided.\n",
    "# IMPORTANT: If the question is not related to CSU policies, respond with: \n",
    "# \"I'm sorry, I can only answer questions related to CSU policies. Could you please rephrase your query accordingly?\"\n",
    "# Question: {question}\n",
    "# Context: {context}\n",
    "# Answer:\n",
    "# \"\"\"\n",
    "\n",
    "# question_prompt_template = \"\"\"\n",
    "# You are a highly knowledgeable assistant with deep expertise in CSU policies. Your responses must strictly pertain to CSU policies and internal policy matters.\n",
    "# IMPORTANT: If the user's question is not about CSU policies or policy-related information, immediately respond with:\n",
    "# \"I'm sorry, I can only answer questions related to CSU policies. Could you please rephrase your query accordingly?\"\n",
    "# Do not provide any additional content in that case.\n",
    "# Otherwise, answer the following question using the context provided.\n",
    "# Question: {query}\n",
    "# Context: {context}\n",
    "# Answer:\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# question_prompt = PromptTemplate(\n",
    "#     input_variables=[\"question\", \"context\"],\n",
    "#     template=\"\"\"\n",
    "# You are a highly knowledgeable assistant with deep expertise in CSU policies.\n",
    "# Only answer questions related to CSU policies.\n",
    "# If the question is not related to CSU policies, respond with:\n",
    "# \"I'm sorry, I can only answer questions related to CSU policies. Could you please rephrase your query accordingly?\"\n",
    "\n",
    "# Question: {question}\n",
    "# Context: {context}\n",
    "# Answer:\n",
    "# \"\"\",\n",
    "# )\n",
    "\n",
    "# question_prompt_template = \"\"\"\n",
    "# You are a CSU Policy Assistant. You are only allowed to answer questions directly related to California State University policies using official policy documents as your source.\n",
    "# If the user's question is not related to CSU policies, respond exactly with:\n",
    "# \"I'm sorry, I can only answer questions related to CSU policies. Could you please rephrase your query accordingly?\"\n",
    "# If the user's question is unclear, ask for clarification.\n",
    "# Otherwise, answer the question using the context provided.\n",
    "\n",
    "# Question: {question}\n",
    "# Context: {context}\n",
    "# Answer:\n",
    "# \"\"\"\n",
    "\n",
    "question_prompt_template = \"\"\"\n",
    "You are a CSU Policy Assistant. Your job is to answer ONLY questions that are directly about California State University (CSU) policies, using official policy documents as your source.\n",
    "\n",
    "Step 1: Before answering, check if the user's question is about CSU policies.\n",
    "- If the question is NOT about CSU policies, respond ONLY with:\n",
    "\"I'm sorry, I can only answer questions related to CSU policies. Could you please rephrase your query accordingly?\"\n",
    "- Do NOT attempt to answer or provide any information outside CSU policies.\n",
    "\n",
    "Step 2: If the question IS about CSU policies:\n",
    "- If unclear, ask the user to clarify.\n",
    "- Otherwise, answer using the provided context.\n",
    "\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "355651ba-a157-4fb2-93f9-0d244d6c5c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine_prompt_template = \"\"\"\n",
    "# The initial answer is: {existing_answer}\n",
    "# Additional context: {context}\n",
    "# IMPORTANT: Ensure the question is clearly related to CSU policies. \n",
    "# If it is not, respond with: \n",
    "# \"I'm sorry, I can only answer questions related to CSU policies. Could you please ask a question related to CSU policies?\"\n",
    "# Otherwise, refine and elaborate on the answer, providing clear details and citing evidence where applicable.\n",
    "# Refined answer:\n",
    "# \"\"\"\n",
    "# refine_prompt_template = \"\"\"\n",
    "# The initial answer is: {existing_answer}\n",
    "# Additional context: {context}\n",
    "\n",
    "# IMPORTANT: Before refining, ensure the question is clearly related to CSU policies.\n",
    "# If you determine that the query is off-topic, immediately respond with:\n",
    "# \"I'm sorry, I can only answer questions related to CSU policies. Could you please ask a question related to CSU policies?\"\n",
    "# Otherwise, please refine and elaborate on the answer, providing clear details and citing evidence as needed.\n",
    "# Refined answer:\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# refine_prompt_template = \"\"\"\n",
    "# [INTERNAL: If the question contains \"summarize\", \"clarify\", or \"rephrase\", do NOT output the off-topic message; simply refine the previous answer.]\n",
    "\n",
    "# The initial answer is: {existing_answer}\n",
    "# Additional context: {context}\n",
    "\n",
    "# IMPORTANT: If the new context does not clearly indicate that the question pertains to CSU policies and no follow-up instruction is present, respond with exactly:\n",
    "# \"I'm sorry, I can only answer questions related to CSU policies. Could you please ask a question related to CSU policies?\"\n",
    "# Otherwise, refine and expand the answer.\n",
    "\n",
    "# Refined answer:\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "refine_prompt_template = \"\"\"\n",
    "You are a CSU Policy Assistant. Your response must be strictly based on CSU policies.\n",
    "\n",
    "Step 1: Check if the question or additional context is about CSU policies.\n",
    "- If NOT, respond ONLY with:\n",
    "\"I'm sorry, I can only answer questions related to CSU policies. Could you please ask a question related to CSU policies?\"\n",
    "\n",
    "Step 2: If it IS about CSU policies, refine and expand the answer using the context provided.\n",
    "\n",
    "The initial answer is: {existing_answer}\n",
    "Additional context: {context}\n",
    "Refined answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c92581a-2845-430d-8921-8c15f98f947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating PromptTemplate objects\n",
    "question_prompt = PromptTemplate(\n",
    "    template=question_prompt_template,\n",
    "    input_variables=[\"question\", \"context\"]\n",
    ")\n",
    "refine_prompt = PromptTemplate(\n",
    "    template=refine_prompt_template,\n",
    "    input_variables=[\"existing_answer\", \"context\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e1cc72-b771-4c7f-b8a9-222f469d9817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bd672e1-76c6-4e3b-ab33-55ee0a5c8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass RetrievalQA to allow extra chain_type_kwargs.\n",
    "class CustomRetrievalQA(RetrievalQA):\n",
    "    class Config:\n",
    "        extra = Extra.allow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05bc7b2e-1f6f-4cae-9bd6-4a9fca88a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_csu_policy_question(query: str) -> bool:\n",
    "    \"\"\"Check if the query relates to CSU policies using keywords.\"\"\"\n",
    "    csu_keywords = [\"CSU\", \"California State University\", \"policy\", \"academic integrity\", \"code of conduct\"]\n",
    "    return any(keyword.lower() in query.lower() for keyword in csu_keywords)\n",
    "\n",
    "# Modify your retriever to return empty results for non-policy questions\n",
    "class PolicyFilteredRetriever(EnsembleRetriever):\n",
    "    def get_relevant_documents(self, query: str):\n",
    "        if not is_csu_policy_question(query):\n",
    "            return []  # Return empty list for non-policy questions\n",
    "        return super().get_relevant_documents(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0124d4e8-a1e8-43b5-bd7f-f6c9cfa703d1",
   "metadata": {},
   "source": [
    "#### Creating Hybrid Retriever (Combines Semantic, Keyword & Graph Retrieval)\n",
    "\n",
    "I'm creating a is a custom hybrid retriever class that:\n",
    "1. Retrieves documents via semantic and keyword search.\n",
    "2. Uses the graph to add neighboring nodes of the retrieved chunks (for additional context).\n",
    "3. Deduplicates and returns a final list of relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6cff1a63-821b-4622-b417-2a9f1291f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridGraphRetriever(BaseRetriever, BaseModel):\n",
    "    semantic_retriever: Any\n",
    "    keyword_retriever: Any\n",
    "    policy_graph: nx.Graph\n",
    "    top_k: int = Field(default=5)\n",
    "    graph_hops: int = Field(default=1)\n",
    "\n",
    "    class Config:\n",
    "        extra = \"allow\"\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        sem_docs = self.semantic_retriever.get_relevant_documents(query)\n",
    "        key_docs = self.keyword_retriever.get_relevant_documents(query)\n",
    "        combined = sem_docs + key_docs\n",
    "        expanded_docs = combined.copy()\n",
    "        for doc in combined:\n",
    "            for node, data in self.policy_graph.nodes(data=True):\n",
    "                if data[\"doc\"].page_content.strip() == doc.page_content.strip():\n",
    "                    neighbors = nx.single_source_shortest_path_length(self.policy_graph, node, cutoff=self.graph_hops)\n",
    "                    for n in neighbors:\n",
    "                        neighbor_doc = self.policy_graph.nodes[n][\"doc\"]\n",
    "                        expanded_docs.append(neighbor_doc)\n",
    "                    break\n",
    "        seen = {}\n",
    "        for doc in expanded_docs:\n",
    "            key = (doc.metadata.get(\"policy_title\", \"\"), doc.metadata.get(\"page\", \"\"), doc.page_content)\n",
    "            seen[key] = doc\n",
    "        unique_docs = list(seen.values())\n",
    "        return unique_docs[:self.top_k]\n",
    "\n",
    "    async def _aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        raise NotImplementedError(\"Async retrieval is not implemented for HybridGraphRetriever.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "beb223c2-8630-49cd-bb6e-169a78f8fcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: HybridGraphRetriever with approximate graph is ready.\n"
     ]
    }
   ],
   "source": [
    "hybrid_retriever = HybridGraphRetriever(\n",
    "    semantic_retriever=semantic_retriever,\n",
    "    keyword_retriever=keyword_retriever,\n",
    "    policy_graph=policy_graph,\n",
    "    top_k=5,\n",
    "    graph_hops=1\n",
    ")\n",
    "\n",
    "# hybrid_retriever = PolicyFilteredRetriever(retrievers=[bm25_retriever, tfidf_retriever], weights=[0.5, 0.5])\n",
    "\n",
    "print(\"[INFO]: HybridGraphRetriever with approximate graph is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "11d307d6-bcc3-47f4-894a-c22d396f05d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom ConversationalRetrievalChain subclass that allows extra keys.\n",
    "class CustomConversationalRetrievalChain(ConversationalRetrievalChain):\n",
    "    class Config:\n",
    "        extra = Extra.allow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9d7eae9-a69d-4e25-a6ba-bbd0ebf3df4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Custom refine documents chain is ready.\n"
     ]
    }
   ],
   "source": [
    "# 2. Create the LLMs\n",
    "llm = Ollama(model=\"mistral\", temperature=0.3)\n",
    "\n",
    "initial_llm_chain = LLMChain(llm=llm, prompt=question_prompt)\n",
    "refine_llm_chain = LLMChain(llm=llm, prompt=refine_prompt)\n",
    "\n",
    "combine_docs_chain = RefineDocumentsChain(\n",
    "    initial_llm_chain=initial_llm_chain,\n",
    "    refine_llm_chain=refine_llm_chain,\n",
    "    document_variable_name=\"context\",\n",
    "    initial_response_name=\"existing_answer\"\n",
    ")\n",
    "print(\"[INFO]: Custom refine documents chain is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76c186a7-3f3c-4f2d-97f7-35519afaad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condense_question_prompt = PromptTemplate(\n",
    "#     input_variables=[\"chat_history\", \"question\"],\n",
    "#     template=\"\"\"\n",
    "# Given the following conversation history and a follow-up question, rephrase the follow-up question into a standalone query.\n",
    "\n",
    "# Chat History:\n",
    "# {chat_history}\n",
    "# Follow-up question: {question}\n",
    "# Standalone question:\n",
    "# \"\"\"\n",
    "# )\n",
    "# question_generator = LLMChain(llm=llm, prompt=condense_question_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8106dcc9-1510-4ae3-9821-bcb0903883ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_question_prompt = PromptTemplate(\n",
    "    template=\"{question}\",\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "question_generator = LLMChain(llm=llm, prompt=dummy_question_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "04807f2c-386b-4ca0-a14f-f2341f33e2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✅] Custom ConversationalRetrievalChain is ready.\n"
     ]
    }
   ],
   "source": [
    "# memory = ConversationBufferMemory(\n",
    "#     memory_key=\"chat_history\", \n",
    "#     output_key=\"answer\", \n",
    "#     return_messages=True\n",
    "# )\n",
    "# rag_chain = CustomRetrievalQA.from_chain_type(\n",
    "#     llm=llm_for_chain,\n",
    "#     chain_type=\"refine\",\n",
    "\n",
    "\n",
    " #     retriever=hybrid_retriever,\n",
    "#     return_source_documents=True,\n",
    "#     chain_type_kwargs={\n",
    "#         \"question_prompt\": question_prompt,\n",
    "#         \"refine_prompt\": refine_prompt,\n",
    "#         \"document_variable_name\": \"context\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# rag_chain_custom = CustomConversationalRetrievalChain.from_llm(\n",
    "#     llm=llm_for_chain, \n",
    "#     retriever=hybrid_retriever,\n",
    "#     memory=memory,\n",
    "#     output_key=\"answer\",\n",
    "#     return_source_documents=True,\n",
    "#     chain_type_kwargs={\n",
    "#          \"question_prompt\": question_prompt,\n",
    "#          \"refine_prompt\": refine_prompt,\n",
    "#          \"document_variable_name\": \"context\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", \n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"\n",
    ")\n",
    "\n",
    "rag_chain = ConversationalRetrievalChain(\n",
    "    retriever=hybrid_retriever,               \n",
    "    combine_docs_chain=combine_docs_chain,   \n",
    "    question_generator=question_generator,\n",
    "    memory=memory,\n",
    "    output_key=\"answer\",\n",
    "    return_source_documents=True,\n",
    "    callbacks=[]\n",
    ")\n",
    "print(\"[✅] Custom ConversationalRetrievalChain is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93c9246a-1f8e-43ec-bda2-188adf2ed652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_on_topic(question: str, llm) -> bool:\n",
    "    \"\"\"Use a simple prompt to ask the LLM whether the query is related to CSU policies.\"\"\"\n",
    "    check_prompt = PromptTemplate(\n",
    "        template=\"Is the following question related to CSU policies? Answer with 'yes' or 'no'.\\nQuestion: {question}\",\n",
    "        input_variables=[\"question\"]\n",
    "    )\n",
    "    check_chain = LLMChain(llm=llm, prompt=check_prompt)\n",
    "    response = check_chain.predict(question=question)\n",
    "    return \"yes\" in response.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "af495fa0-7115-49e2-a0d5-9afe783d424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def policy_chatbot(query: str):\n",
    "\n",
    "#     # First, check if the query is on-topic.\n",
    "#     if not is_on_topic(query, llm):\n",
    "#         print(\"\\nI'm sorry, I can only answer questions related to CSU policies. Could you please rephrase your query accordingly?\\n\")\n",
    "#         return\n",
    "    \n",
    "#     # Note: Use \"question\" as the input key.\n",
    "#     result = rag_chain({\"question\": query})\n",
    "#     answer = result.get(\"answer\", \"\")\n",
    "#     source_docs = result.get(\"source_documents\", [])\n",
    "    \n",
    "#     print(f\"\\n💬 Query: {query}\\n\")\n",
    "#     print(f\"🤖 Answer:\\n{answer}\\n\")\n",
    "    \n",
    "#     print(\"📚 References:\")\n",
    "#     for i, doc in enumerate(source_docs, start=1):\n",
    "#         metadata = doc.metadata\n",
    "#         policy_title = metadata.get(\"policy_title\", \"Unknown Policy\")\n",
    "#         policy_url = metadata.get(\"policy_url\", None)\n",
    "#         page = metadata.get(\"page\")\n",
    "#         page_num = page + 1 if isinstance(page, int) else \"?\"\n",
    "#         if policy_url and isinstance(policy_url, str) and policy_url.startswith(\"http\"):\n",
    "#             link = f\"{policy_url}#page={page_num} ({policy_title})\"\n",
    "#         else:\n",
    "#             link = f\"{policy_title} (Page {page_num})\"\n",
    "#         print(f\"[{i}] {link}\")\n",
    "#     print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
    "\n",
    "\n",
    "# def policy_chatbot(question: str):  \n",
    "#     result = rag_chain({\"question\": question})\n",
    "#     answer = result.get(\"answer\", \"\")\n",
    "#     source_docs = result.get(\"source_documents\", [])\n",
    "    \n",
    "#     print(f\"\\n💬 Query: {question}\\n\")\n",
    "#     print(f\"🤖 Answer:\\n{answer}\\n\")\n",
    "#     print(\"📚 References:\")\n",
    "#     for i, doc in enumerate(source_docs, 1):\n",
    "#         meta = doc.metadata\n",
    "#         title = meta.get(\"policy_title\", \"Unknown Policy\")\n",
    "#         url = meta.get(\"policy_url\", \"\")\n",
    "#         page = meta.get(\"page\")\n",
    "#         page_disp = page + 1 if isinstance(page, int) else \"?\"\n",
    "#         if url:\n",
    "#             print(f\"[{i}] {url}#page={page_disp} ({title})\")\n",
    "#         else:\n",
    "#             print(f\"[{i}] {title} (Page {page_disp})\")\n",
    "#     print(\"\\n\" + \"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "787fee27-268f-43ae-b2d3-5be764e924c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_on_topic(question: str) -> bool:\n",
    "    \"\"\"\n",
    "    Uses a simple LLMChain to check if the question is directly related to CSU policies.\n",
    "    Returns True if the answer is 'yes', otherwise False.\n",
    "    \"\"\"\n",
    "    on_topic_prompt = PromptTemplate(\n",
    "        template=\"Is the following question related to CSU policies? Answer only 'yes' or 'no'.\\nQuestion: {question}\",\n",
    "        input_variables=[\"question\"]\n",
    "    )\n",
    "    on_topic_chain = LLMChain(llm=llm, prompt=on_topic_prompt)\n",
    "    response = on_topic_chain.predict(question=question)\n",
    "    return \"yes\" in response.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1322b753-2039-4776-bcfa-f8e801b580d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_chatbot(question: str):\n",
    "    # Pre-check: if question is off-topic, immediately return the fixed off-topic message.\n",
    "    if not is_on_topic(question):\n",
    "        print(\"\\nI'm sorry, I can only answer questions related to CSU policies. Could you please rephrase your query accordingly?\\n\")\n",
    "        return\n",
    "\n",
    "    result = rag_chain({\"question\": question})\n",
    "    answer = result.get(\"answer\", \"\")\n",
    "    source_docs = result.get(\"source_documents\", [])\n",
    "    \n",
    "    print(f\"\\n💬 Query: {question}\\n\")\n",
    "    print(f\"🤖 Answer:\\n{answer}\\n\")\n",
    "    print(\"📚 References:\")\n",
    "    for i, doc in enumerate(source_docs, start=1):\n",
    "        meta = doc.metadata\n",
    "        title = meta.get(\"policy_title\", \"Unknown Policy\")\n",
    "        url = meta.get(\"policy_url\", \"\")\n",
    "        page = meta.get(\"page\")\n",
    "        page_disp = page + 1 if isinstance(page, int) else \"?\"\n",
    "        if url and isinstance(url, str) and url.startswith(\"http\"):\n",
    "            print(f\"[{i}] {url}#page={page_disp} ({title})\")\n",
    "        else:\n",
    "            print(f\"[{i}] {title} (Page {page_disp})\")\n",
    "    print(\"\\n\" + \"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70664aa3-8bc8-4b4a-aae3-2596b9b8f5f1",
   "metadata": {},
   "source": [
    "#### Trying our chatbot with different queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8aa702ca-9a1d-4d36-b14b-280ca99230a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Query: What are the approval procedures for academic freedom-related policies?\n",
      "\n",
      "🤖 Answer:\n",
      " To provide more specific information regarding your inquiry, here are the relevant CSU policies related to the topics you've mentioned:\n",
      "\n",
      "1. Policies on Student Fees and Financial Aid can be found in the Tuition, Fees, and Financial Aid section of each campus's catalog. Each campus may have slightly different policies, so it is best to consult your specific campus's catalog. (Referenced policy: Tuition, Fees, and Financial Aid)\n",
      "\n",
      "2. Policies on the Transfer of Credit Earned at Other Institutions can be found in the Transfer Credit section of each campus's catalog. Again, each campus may have slightly different policies, so it is best to consult your specific campus's catalog. (Referenced policy: Transfer Credit)\n",
      "\n",
      "3. Catalog Rights policies are outlined in the Catalog Rights and Academic Standards section of each campus's catalog. Each campus may have slightly different procedures, so it is best to consult your specific campus's catalog. (Referenced policy: Catalog Rights)\n",
      "\n",
      "4. Policies and Procedures for Obtaining a Leave of Absence or Withdrawing From the University can be found in the Leaves of Absence and Withdrawal section of each campus's catalog. Again, each campus may have slightly different procedures, so it is best to consult your specific campus's catalog. (Referenced policy: Leaves of Absence and Withdrawal)\n",
      "\n",
      "5. Policy for Reinstatement can be found in the Academic Standing and Probation section of each campus's catalog. Each campus may have slightly different policies, so it is best to consult your specific campus's catalog. (Referenced policy: Academic Standing and Probation)\n",
      "\n",
      "6. Policies and Procedures Regarding Student Grievances are typically outlined in the Student Grievance Policy or Undergraduate Petitions section of each campus's catalog. Again, each campus may have slightly different procedures, so it is best to consult your specific campus's catalog. (Referenced policy: Student Grievance)\n",
      "\n",
      "7. Policies on Harassment and Discrimination can be found in the Non-Discrimination and Equal Opportunity section of each campus's catalog. Each campus may have slightly different policies, so it is best to consult your specific campus's catalog. (Referenced policy: Non-Discrimination and Equal Opportunity)\n",
      "\n",
      "8. Policies on Professional Ethics and Academic Integrity can be found in the Academic Integrity section of each campus's catalog. Each campus may have slightly different policies, so it is best to consult your specific campus's catalog. (Referenced policy: Academic Integrity)\n",
      "\n",
      "9. Institutional Research Guidelines are typically outlined in the Institutional Research and Planning section of each campus's catalog or on the institutional research website. Again, each campus may have slightly different guidelines, so it is best to consult your specific campus's resources. (Referenced policy: Institutional Research and Planning)\n",
      "\n",
      "For additional information, you can refer to the official copies of these policies at http://calstate.policystat.com/. Please note that these policies are subject to change during their periodic reviews.\n",
      "\n",
      "📚 References:\n",
      "[1] https://calstate.policystat.com/policy/17347260/#page=1 (academic freedom policy)\n",
      "[2] Interim Systemwide Time- Place and Manner Policy (Page 2)\n",
      "[3] https://calstate.policystat.com/policy/17347260/#page=1 (academic freedom policy)\n",
      "[4] https://calstate.policystat.com/policy/17685310/#page=12 (csu applied and professional doctoral programs)\n",
      "[5] https://calstate.policystat.com/policy/17685310/#page=12 (csu applied and professional doctoral programs)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_chatbot(\"What are the approval procedures for academic freedom-related policies?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ccc8fd83-713f-43ef-a706-8bf7695783cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm sorry, I can only answer questions related to CSU policies. Could you please rephrase your query accordingly?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How many states are there in USA?\"\n",
    "policy_chatbot(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "15767702-94af-49d3-b89c-75d3dba42156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm sorry, I can only answer questions related to CSU policies. Could you please rephrase your query accordingly?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_chatbot(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "61d1c5d3-3dfa-43a4-9e71-1504ad2bd4fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Query: What is the annual fees of MS in CS fees at San Jose State University?\n",
      "\n",
      "🤖 Answer:\n",
      " The fee for international students in the Master of Science (MS) in Computer Science program at San Jose State University may have been the Student Success, Excellence and Technology Fee during certain academic years, which was set at $630 per term according to the CSU policy document from 2013-14. However, it's essential to note that this fee is not a systemwide CSU policy but rather a fee that may be assessed by individual academic programs within the university.\n",
      "\n",
      "For the 2023-24 academic year, the nonresident tuition fee per unit is $396 for semester-based programs and $264 for quarter-based programs. The total nonresident tuition paid per term will be determined by the number of units taken.\n",
      "\n",
      "In addition to this, a supplemental Graduate Business Professional Fee has been set at rates of $231 per term for graduate students in certain programs. For accurate and current information about fees at San Jose State University, please visit their official website: https://sjsu.edu/admissions-records/graduate-studies/index.php.\n",
      "\n",
      "For more detailed information about tuition fees across all CSU campuses, including different calendars, regular students, part-time students, and summer terms, please refer to the Budget Office website: http://www.calstate.edu/budget/student-fees/fee-rates/.\n",
      "\n",
      "The average CSU 2023-24 academic year, resident, undergraduate student basic tuition and other mandatory fees required to apply to, enroll in, or attend the university is $7,622 ($5,742 tuition fee plus $1,880 average campus-based fees). However, the costs paid by individual students will vary depending on the university, program, and whether a student is part-time, full-time, resident, or nonresident. The Full-Time Equivalent Student (FTES) rate for the 2023-24 academic year is $7,761.\n",
      "\n",
      "📚 References:\n",
      "[1] Category III Fees- Category IV Fee- San Francisco State University (Page 1)\n",
      "[2] https://calstate.policystat.com/policy/15274496/#page=11 (csu mandatory catalog copy)\n",
      "[3] https://calstate.policystat.com/policy/8843098/#page=28 (resolutions of the board of trustees 2010)\n",
      "[4] Student Success- Excellence and Technology Fee- San José State University (Page 1)\n",
      "[5] https://calstate.policystat.com/policy/15274496/#page=24 (csu mandatory catalog copy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the annual fees of MS in CS fees at San Jose State University?\"\n",
    "policy_chatbot(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59928b-c77d-4177-8eeb-76e0a647aeff",
   "metadata": {},
   "source": [
    "#### Experimenting complex queries\n",
    "\n",
    "This below query requires the chatbot to retrieve information from the Academic Freedom Policy (which discusses research freedom and potential conflicts) and additional policy documents related to research funding or conflict of interest. The answer must integrate details from more than one policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ad5cba20-0902-4cd5-a6c4-cbe923f8c2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Query: How does the university policy address conflicts between faculty research priorities and commercial interests, and what approval procedures are in place to manage these conflicts?\n",
      "\n",
      "🤖 Answer:\n",
      " In the California State University (CSU), conflicts of interest are managed, resolved, and reported for various activities, including business transactions involving campus alumni associations and personal or business affairs of directors, officers, or staff members. These transactions require advance approval by the governing body.\n",
      "\n",
      "In cases where a conflict of interest is identified, an independent review committee is appointed to assess and make recommendations for its management. This process aligns with the CSU's commitment to maintaining academic integrity and adhering to both Federal Conflict of Interest regulations and California Conflict of Interest requirements.\n",
      "\n",
      "For federally funded research, each CSU campus assists investigators, students, and research staff in determining potential conflicts and manages or reports them according to applicable policy or regulation. This process includes the appointment of an independent review committee.\n",
      "\n",
      "In terms of California State Conflict of Interest requirements, the CSU complies with various policies such as the HR Conflict of Interest Policies, HR POI COI Policy, and CSU Ethics Training. These requirements were previously referred to as Code HR 2015-05. For more detailed information on these procedures, please refer to the specific CSU policy document related to conflicts of interest.\n",
      "\n",
      "📚 References:\n",
      "[1] https://calstate.policystat.com/policy/16577430/#page=12 (sponsored programs administration)\n",
      "[2] https://calstate.policystat.com/policy/16577430/#page=4 (sponsored programs administration)\n",
      "[3] https://calstate.policystat.com/policy/16577430/#page=4 (sponsored programs administration)\n",
      "[4] https://calstate.policystat.com/policy/8902999/#page=49 (resolutions of the board of trustees 2002)\n",
      "[5] https://calstate.policystat.com/policy/16577430/#page=7 (sponsored programs administration)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_chatbot(\"How does the university policy address conflicts between faculty research priorities and commercial interests, and what approval procedures are in place to manage these conflicts?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11259d7d-f237-497a-9507-20ec9aa9854d",
   "metadata": {},
   "source": [
    "**Complex Query-2:**\n",
    "\n",
    "This below query demands a comparison between two distinct policies. The policystat chatbot needs to extract guidelines from both the Academic Access Policy and the Student Code of Conduct (or similar documents) and then perform a synthesis to highlight the differences and impacts on enforcement.\n",
    "\n",
    "**How it works:**\n",
    "1. The RAG pipeline retrieves chunks from both policies—semantic search picks up nuanced guidelines while keyword search fetches exact phrases like “faculty responsibilities” or “enforcement.”\n",
    "2. GraphRAG further enhances the process by connecting sections that use similar language across policies.\n",
    "3. The LLM then collates these details into a comparative answer with contextual references that indicate the policy source and page number for each piece of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "600000d4-e98b-47fa-a09d-621f8307c04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Query: What are the key differences between the Academic Access Policy and the Student Code of Conduct regarding faculty responsibilities, and how do these differences influence policy enforcement at the institution?\n",
      "\n",
      "🤖 Answer:\n",
      " In the California State University (CSU), the Student Conduct Code applies to all students, including applicants, enrolled students, students between academic terms, graduates awaiting degrees, and students who withdraw from school while a disciplinary matter is pending. Any behavior that threatens the safety or security of the university community, or substantially disrupts the functions or operation of the university may lead to disciplinary action, regardless of whether a law enforcement investigation has concluded. The Student Conduct Process outlines the procedure for addressing these violations and may result in various sanctions such as restitution, loss of financial aid, educational and remedial sanctions, denial of access to Campus or persons, disciplinary probation or suspension, among others. The aim of this process is to maintain a positive and productive university environment for all students.\n",
      "\n",
      "📚 References:\n",
      "[1] Interim Systemwide Time- Place and Manner Policy (Page 14)\n",
      "[2] https://calstate.policystat.com/policy/17647883/#page=25 (interim csu nondiscrimination policy)\n",
      "[3] https://calstate.policystat.com/policy/15274496/#page=63 (csu mandatory catalog copy)\n",
      "[4] Interim Systemwide Time- Place and Manner Policy (Page 13)\n",
      "[5] https://calstate.policystat.com/policy/15274496/#page=66 (csu mandatory catalog copy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_chatbot(\"What are the key differences between the Academic Access Policy and the Student Code of Conduct regarding faculty responsibilities, and how do these differences influence policy enforcement at the institution?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3d4fa193-7a5a-40aa-ae64-206ef3e36fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Query: Could you please summerize the above answer?\n",
      "\n",
      "🤖 Answer:\n",
      " Inquiries about the handling of allegations within the California State University (CSU) system often concern the investigative process and evidence collection in such cases, particularly when it comes to Title IX sexual harassment policy. Here's a more detailed explanation:\n",
      "\n",
      "1. Allegation: An accusation made against an individual within the CSU system, which can encompass a broad spectrum of issues related to Title IX, such as sexual misconduct or gender-based discrimination.\n",
      "\n",
      "2. Investigative Process: When an allegation is reported, it triggers an investigation. This process involves several steps: gathering evidence, interviewing relevant parties, and reviewing any available documentation. The goal is to establish whether the allegations are substantiated or not. (California State University, 2021)\n",
      "\n",
      "3. Evidence Collection: In addition to the standard evidence considered during an investigation, such as witness statements, physical evidence, emails, and any other relevant documentation, the Investigator may attempt to collect additional relevant evidence. The specific evidence will depend on the nature of the allegations. (California State University, n.d.)\n",
      "\n",
      "4. Preponderance of the Evidence Standard: This standard, used in CSU investigations, requires that it be more likely than not that a violation occurred. In other words, if the evidence shows that it is more probable than not that the allegation is true, then the allegation is substantiated.\n",
      "\n",
      "5. Determination of Substantiation: Based on the evidence gathered during the investigation, a determination is made as to whether the allegations are substantiated or not. If they are found to be substantiated, appropriate action is taken, which may range from counseling and education to suspension or expulsion, depending on the severity of the violation and the individual's prior record.\n",
      "\n",
      "6. Notification: Within a specified time frame, the campus administrator will notify the complainant in writing of the outcome. The notification should include a summary of the allegations, a description of the investigative process, and the determination of whether the allegations were found to be substantiated or not. For example, if academic dishonesty is found, the student may receive a grade adjustment or be subjected to academic probation. (California State University, 2021)\n",
      "\n",
      "7. Confidentiality: It's important to note that all records of investigations will be kept confidential, except in cases where disclosure is necessary for the administration of justice or as required by law. The CSU system prioritizes the privacy interests of each person involved in the situation addressed by the response. (California State University, 2021)\n",
      "\n",
      "8. Additional Information: Any evidence available but not disclosed during the investigation might not be considered in any findings made, and likely will not be considered for purposes of appeal. The Complainant and Respondent will be provided with periodic status updates in accordance with the timelines established in these Procedures. (California State University, n.d.)\n",
      "\n",
      "9. Environmental Impact Report (EIR): In a different context, the handling of allegations within the CSU system does not involve the Final EIR, comments received on the Draft EIR and Final EIR, proceedings before the Board of Trustees relating to the subject Project, including testimony and documentary evidence introduced at such proceedings, or all attachments, documents incorporated, and references made in the documents as specified in items (A) through (C) above.\n",
      "\n",
      "References:\n",
      "- California State University (2021). Title IX Sexual Harassment Policy. Retrieved from https://calstate.edu/TitleIX\n",
      "- California State University, Chico (n.d.). Student Research Symposium. Retrieved from https://www.csuchico.edu/studentresearchsymposium/\n",
      "\n",
      "📚 References:\n",
      "[1] Student-Applicant Complaint Procedure for Alleged Violations of State Law Not Covered by Another CSU Complaint Procedure (Page 3)\n",
      "[2] https://calstate.policystat.com/policy/13640873/#page=4 (definitions of graduate level instruction)\n",
      "[3] Complaint Procedures for Protected Disclosure of Improper Governmental Activities and-or Significant Threats to Health or Safety (Page 7)\n",
      "[4] https://calstate.policystat.com/policy/17647883/#page=21 (interim csu nondiscrimination policy)\n",
      "[5] https://calstate.policystat.com/policy/8998435/#page=44 (resolutions of the board of trustees 2007)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33015e97-1f15-4ed9-8880-0dff109a74a3",
   "metadata": {},
   "source": [
    "**Complex Query-3:**\n",
    "The below query is a multi-faceted query requiring integration of information from several policies. It involves not only the Academic Freedom Policy but also the tenure guidelines and research compliance standards. The answer must present a holistic view that outlines both academic independence and regulatory compliance.\n",
    "\n",
    "**How chatbot works**:\n",
    "The chatbot uses the hybrid retrieval module to gather relevant documents from all three policy areas. Semantic retrieval captures conceptual links about “independence” and “compliance,” while keyword retrieval hones in on technical terms like “tenure” or “regulations.” The graph-based component connects these overlapping concepts across multiple documents. With conversational memory, the system preserves context across turns, and the final answer generated by the LLM includes inline citations that reference the exact policy and page number where each requirement is stated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f1a4f64d-9f4d-4f1c-b07e-0223c9f61d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Query: Considering the university’s policies on academic freedom, tenure, and research compliance, what are the combined requirements for faculty to maintain academic independence while ensuring adherence to institutional regulations? Give me the brief summary of the entire answer in the end.\n",
      "\n",
      "🤖 Answer:\n",
      " Faculty members at California State University (CSU) are entitled to full freedom in research, teaching, and publication as outlined in the Academic Freedom Policy (CSU Executive Order 1096). This includes academic freedom to teach their subject matter without external constraints other than those normally denoted by scholarly standards.\n",
      "\n",
      "In terms of authority, it is important to note that students are also subject to discipline for conduct that threatens the safety or security of the campus community, or substantially disrupts the functions or operation of the University, regardless of whether it occurs on or off campus (5 Cal. Code Regs. § 41301 (d)).\n",
      "\n",
      "Regarding research, faculty have the right to conduct research for pecuniary return (research conducted for financial gain), but any such research must be based upon an understanding with the authorities of the institution. This means that any financial gains from such research must be disclosed and managed appropriately according to CSU policies.\n",
      "\n",
      "The policy is also intended to define, promote, and encourage responsible use of CSU information assets among members of the CSU community. It is not intended to prevent, prohibit, or inhibit the sanctioned use of CSU information assets as required to meet the CSU's core mission and campus objectives.\n",
      "\n",
      "Faculty must adhere to tenure principles and research compliance requirements, which include demonstrating excellence in teaching, research, and service; conducting research ethically and in accordance with relevant laws, regulations, and institutional policies; obtaining necessary approvals for human subjects research; ensuring proper management of animal care and use; maintaining data integrity; and adhering to conflict-of-interest guidelines.\n",
      "\n",
      "Balancing academic freedom with these responsibilities allows for the pursuit of knowledge while ensuring that the work is conducted ethically, responsibly, and in accordance with the institution's values and mission. (Reference: Academic Freedom Policy - CSU Executive Order 1096)\n",
      "\n",
      "The University will not wait for the conclusion of a law enforcement investigation before taking action if there is a threat to the safety or security of the campus community or substantial disruption of the University's functions or operation (additional context from endnote 2).\n",
      "\n",
      "📚 References:\n",
      "[1] https://calstate.policystat.com/policy/17347260/#page=1 (academic freedom policy)\n",
      "[2] Interim Systemwide Time- Place and Manner Policy (Page 2)\n",
      "[3] https://calstate.policystat.com/policy/17347260/#page=1 (academic freedom policy)\n",
      "[4] https://calstate.policystat.com/policy/14685892/#page=1 (information security responsible use policy)\n",
      "[5] https://calstate.policystat.com/policy/17647883/#page=25 (interim csu nondiscrimination policy)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Considering the university’s policies on academic freedom, tenure, and research compliance, what are the combined requirements for faculty to maintain academic independence while ensuring adherence to institutional regulations? Give me the brief summary of the entire answer in the end.\"\n",
    "policy_chatbot(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ab6f8-0030-417c-882c-0fcaa3ca9ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba7461-a42a-42b1-9e21-2f94fe65c72d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
